#!./venv/bin/python
from urllib.parse import urlencode, urlparse, parse_qs

import re

from requests import get
from bs4 import BeautifulSoup

import argparse


def join_search_terms(st):
    return "+".join(st)


def search(stq, results):
    search_url = f"https://www.google.com/search?q={stq}&num={results}"
    print("searching url:", search_url)
    page = get(search_url)
    soup = BeautifulSoup(page.content, 'html.parser')
    links = soup.findAll("a")

    for link in links:
        link_href = link.get('href')
        if "url?q=" in link_href and not "webcache" in link_href:
            print(link.get('href').split("?q=")[1].split("&sa=U")[0])


parser = argparse.ArgumentParser(description='Process some url search terms.')
parser.add_argument('terms', metavar='TERMS', type=str, nargs='+',
                    help='Search terms separated by space', default=[])
parser.add_argument('--results', metavar='N',
                    help='Number of search results. Valid options 10, 20, 30, 40, 50, and 100', default=100)
#
args = parser.parse_args()

print(search(join_search_terms(args.terms), args.results))
